torch>=2.2.0
transformers>=4.40.0
tokenizers>=0.19.0
accelerate>=0.30.0
safetensors>=0.4.0
einops>=0.8.0
omegaconf>=2.3.0
tqdm>=4.66.0

[all]
gated-sparse-attention[dev,eval,training]

[dev]
pytest>=8.0.0
pytest-xdist>=3.5.0
pytest-cov>=5.0.0
black>=24.0.0
isort>=5.13.0
flake8>=7.0.0
mypy>=1.9.0
hypothesis>=6.100.0

[eval]
datasets>=2.19.0
lm-eval>=0.4.2
rouge-score>=0.1.2
sacrebleu>=2.4.0

[training]
deepspeed>=0.14.0
flash-attn>=2.5.0
triton>=2.3.0
bitsandbytes>=0.43.0
wandb>=0.17.0
tensorboard>=2.16.0
